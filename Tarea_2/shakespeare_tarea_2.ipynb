{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Ciencia de Datos: Tarea 2\n",
    "\n",
    "Este notebook contiene el código de base para realizar la Tarea 2 del curso. Puede copiarlo en su propio repositorio y trabajar sobre el mismo.\n",
    "Las **instrucciones para ejecutar el notebook** están en la [página inicial del repositorio](https://gitlab.fing.edu.uy/maestria-cdaa/intro-cd/).\n",
    "\n",
    "**Se espera que no sea necesario revisar el código para corregir la tarea**, ya que todos los resultados y análisis relevantes deberían estar en el **informe en formato PDF**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar dependencias\n",
    "Para esta tarea, se han agregado algunos requerimientos, asegúrese de instalarlos (puede usar el mismo entorno virtual de la Tarea 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /home/fmatonte/.local/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: pandas in /home/fmatonte/.local/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: sqlalchemy<2.0 in /home/fmatonte/.local/lib/python3.8/site-packages (1.4.48)\n",
      "Requirement already satisfied: pymysql in /home/fmatonte/.local/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: seaborn in /home/fmatonte/.local/lib/python3.8/site-packages (0.12.2)\n",
      "Requirement already satisfied: pillow in /home/fmatonte/.local/lib/python3.8/site-packages (9.5.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipywidgets in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter) (8.0.6)\n",
      "Requirement already satisfied: nbconvert in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter) (7.4.0)\n",
      "Requirement already satisfied: notebook in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter) (6.5.4)\n",
      "Requirement already satisfied: qtconsole in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter) (5.4.3)\n",
      "Requirement already satisfied: ipykernel in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter) (6.23.0)\n",
      "Requirement already satisfied: jupyter-console in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/fmatonte/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/fmatonte/.local/lib/python3.8/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /home/fmatonte/.local/lib/python3.8/site-packages (from sqlalchemy<2.0) (2.0.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from seaborn) (3.7.1)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 47.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipywidgets->jupyter) (3.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipywidgets->jupyter) (4.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipywidgets->jupyter) (5.9.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipywidgets->jupyter) (8.12.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.4)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (3.1.2)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (5.8.0)\n",
      "Requirement already satisfied: packaging in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (23.1)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (2.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (2.0.5)\n",
      "Requirement already satisfied: bleach in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (6.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6; python_version < \"3.10\" in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (6.6.0)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (5.3.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.2.2)\n",
      "Requirement already satisfied: defusedxml in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (4.12.2)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbconvert->jupyter) (2.15.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (1.5.6)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: ipython-genutils in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: prometheus-client in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (0.16.0)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (8.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (6.3.1)\n",
      "Requirement already satisfied: argon2-cffi in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (1.0.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (25.0.2)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from qtconsole->jupyter) (2.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: psutil in /home/fmatonte/.local/lib/python3.8/site-packages (from ipykernel->jupyter) (5.9.5)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-console->jupyter) (3.0.38)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fmatonte/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in /home/fmatonte/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/fmatonte/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->jupyter) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in /home/fmatonte/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->jupyter) (4.5.0)\n",
      "Requirement already satisfied: decorator in /home/fmatonte/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->jupyter) (5.1.1)\n",
      "Requirement already satisfied: stack-data in /home/fmatonte/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->jupyter) (0.6.2)\n",
      "Requirement already satisfied: pickleshare in /home/fmatonte/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->jupyter) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/lib/python3/dist-packages (from ipython>=6.1.0->ipywidgets->jupyter) (4.6.0)\n",
      "Requirement already satisfied: backcall in /home/fmatonte/.local/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbformat>=5.1->nbconvert->jupyter) (4.17.3)\n",
      "Requirement already satisfied: fastjsonschema in /home/fmatonte/.local/lib/python3.8/site-packages (from nbformat>=5.1->nbconvert->jupyter) (2.16.3)\n",
      "Requirement already satisfied: webencodings>=0.4 in /home/fmatonte/.local/lib/python3.8/site-packages (from tinycss2->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/fmatonte/.local/lib/python3.8/site-packages (from importlib-metadata>=3.6; python_version < \"3.10\"->nbconvert->jupyter) (3.15.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-core>=4.7->nbconvert->jupyter) (3.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/fmatonte/.local/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.4.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /home/fmatonte/.local/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/fmatonte/.local/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (0.2.3)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/fmatonte/.local/lib/python3.8/site-packages (from nbclassic>=0.4.7->notebook->jupyter) (2.5.0)\n",
      "Requirement already satisfied: wcwidth in /home/fmatonte/.local/lib/python3.8/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->jupyter) (0.8.3)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->jupyter) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/fmatonte/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->jupyter) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->jupyter) (1.2.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10; python_version < \"3.9\" in /home/fmatonte/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (1.3.10)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter) (0.19.3)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\n",
      "Requirement already satisfied: websocket-client in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: jupyter-server-terminals in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.4.4)\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.6.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (3.6.2)\n",
      "Requirement already satisfied: pycparser in /home/fmatonte/.local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/lib/python3/dist-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (5.3.1)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/fmatonte/.local/lib/python3.8/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (2.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/fmatonte/.local/lib/python3.8/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter) (1.3.0)\n",
      "Installing collected packages: scipy, threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter pandas \"sqlalchemy<2.0\" pymysql seaborn pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conexión a la Base y Lectura de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando a la base...\n",
      "Cargando tabla desde CSV: data/shakespeare/paragraphs.csv\n",
      "Cargando tabla desde CSV: data/shakespeare/characters.csv\n",
      "Cargando tabla desde CSV: data/shakespeare/works.csv\n",
      "Cargando tabla desde CSV: data/shakespeare/chapters.csv\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data\") / \"shakespeare\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_table(table_name, engine):\n",
    "    \"\"\"\n",
    "    Leer la tabla con SQL y guardarla como CSV,\n",
    "    o cargarla desde el CSV si ya existe\n",
    "    \"\"\"\n",
    "    path_table = data_dir / f\"{table_name}.csv\"\n",
    "    if not path_table.exists():\n",
    "        print(f\"Consultando tabla con SQL: {table_name}\")\n",
    "        t0 = time()\n",
    "        df_table = pd.read_sql(f\"SELECT * FROM {table_name}\", engine)\n",
    "        t1 = time()\n",
    "        print(f\"Tiempo: {t1 - t0:.1f} segundos\")\n",
    "\n",
    "        print(f\"Guardando: {path_table}\\n\")\n",
    "        df_table.to_csv(path_table)\n",
    "    else:\n",
    "        print(f\"Cargando tabla desde CSV: {path_table}\")\n",
    "        df_table = pd.read_csv(path_table, index_col=[0])\n",
    "    return df_table\n",
    "\n",
    "\n",
    "print(\"Conectando a la base...\")\n",
    "conn_str = \"mysql+pymysql://guest:relational@relational.fit.cvut.cz:3306/Shakespeare\"\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Todos los párrafos de todas las obras\n",
    "df_paragraphs = load_table(\"paragraphs\", engine)\n",
    "\n",
    "df_characters = load_table(\"characters\", engine)\n",
    "\n",
    "df_works = load_table(\"works\", engine)\n",
    "\n",
    "df_chapters = load_table(\"chapters\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlainText</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Enter DUKE ORSINO, CURIO, and other Lords; Mu...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If music be the food of love, play on;\\nGive m...</td>\n",
       "      <td>if music be the food of love  play on  give me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will you go hunt, my lord?</td>\n",
       "      <td>will you go hunt  my lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What, Curio?</td>\n",
       "      <td>what  curio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The hart.</td>\n",
       "      <td>the hart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35460</th>\n",
       "      <td>That she is living,\\nWere it but told you, sho...</td>\n",
       "      <td>that she is living  were it but told you  shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35461</th>\n",
       "      <td>You gods, look down\\nAnd from your sacred vial...</td>\n",
       "      <td>you gods  look down and from your sacred vials...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35462</th>\n",
       "      <td>There's time enough for that;\\nLest they desir...</td>\n",
       "      <td>there time enough for that  lest they desire u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35463</th>\n",
       "      <td>O, peace, Paulina!\\nThou shouldst a husband ta...</td>\n",
       "      <td>o  peace  paulina  thou shouldst a husband tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35464</th>\n",
       "      <td>[Exeunt]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35465 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               PlainText   \n",
       "0      [Enter DUKE ORSINO, CURIO, and other Lords; Mu...  \\\n",
       "1      If music be the food of love, play on;\\nGive m...   \n",
       "2                             Will you go hunt, my lord?   \n",
       "3                                           What, Curio?   \n",
       "4                                              The hart.   \n",
       "...                                                  ...   \n",
       "35460  That she is living,\\nWere it but told you, sho...   \n",
       "35461  You gods, look down\\nAnd from your sacred vial...   \n",
       "35462  There's time enough for that;\\nLest they desir...   \n",
       "35463  O, peace, Paulina!\\nThou shouldst a husband ta...   \n",
       "35464                                           [Exeunt]   \n",
       "\n",
       "                                               CleanText  \n",
       "0                                                    NaN  \n",
       "1      if music be the food of love  play on  give me...  \n",
       "2                             will you go hunt  my lord   \n",
       "3                                           what  curio   \n",
       "4                                              the hart   \n",
       "...                                                  ...  \n",
       "35460  that she is living  were it but told you  shou...  \n",
       "35461  you gods  look down and from your sacred vials...  \n",
       "35462  there time enough for that  lest they desire u...  \n",
       "35463  o  peace  paulina  thou shouldst a husband tak...  \n",
       "35464                                                NaN  \n",
       "\n",
       "[35465 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DONE: Version de clean_text() actualizada a la misma usada en la Tarea_1\n",
    "def clean_text(df, column_name):\n",
    "    # Convertir todo a minúsculas\n",
    "    result = df[column_name].str.lower()\n",
    "\n",
    "    # se quitan las indicaciones de escena\n",
    "    result = result.loc[~result.str.startswith(\"[\") & ~result.str.endswith(\"]\")]\n",
    "\n",
    "    # Quitar signos de puntuación y cambiarlos por espacios (\" \")\n",
    "    # TODO: completar signos de puntuación faltantes\n",
    "    for punc in [\"\\n\", \",\", \";\", \".\", \"?\", \"!\", \":\", \"-\",\"--\", \"\\\"\", \"(\", \")\",\"&c\",\"[\",\"]\",]:\n",
    "        result = result.str.replace(punc, \" \")\n",
    "    \n",
    "    # Cambiar las contracciones por sus palabras ---> TAMBIEN PARA LAS NEGATIVAS?\n",
    "    contractions = [{\"contraction\": \"'re\", \"word\": \"are\"}, {\"contraction\": \"'ll\", \"word\": \"will\"}, \n",
    "                    {\"contraction\": \"'ve\", \"word\": \"have\"}, {\"contraction\": \"'twas\", \"word\": \"it was\"}]    \n",
    "    for c in contractions:\n",
    "        result = result.str.replace(c[\"contraction\"], c[\"word\"])\n",
    "        \n",
    "    # Para las contracciones que no detectamos eliminamos el apostrofe y el palabra abreviada.\n",
    "    \n",
    "    result = result.str.replace(r\"'[^']*?\\s\", \" \", regex=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    #cambiar digitos por sus palabras\n",
    "    digits =[{'digit':'0','word':'zero'},{'digit':'1','word':'one'},{'digit':'2','word':'two'},{'digit':'3','word':'three'},\n",
    "             {'digit':'4','word':'four'},{'digit':'5','word':'five'},{'digit':'6','word':'six'},{'digit':'7','word':'seven'},\n",
    "             {'digit':'8','word':'eight'},{'digit':'9','word':'nine'}]\n",
    "\n",
    "    for d in digits:\n",
    "        result = result.str.replace(d[\"digit\"], d[\"word\"])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Creamos una nueva columna CleanText a partir de PlainText\n",
    "df_paragraphs[\"CleanText\"] = clean_text(df_paragraphs, \"PlainText\")\n",
    "\n",
    "# Veamos la diferencia\n",
    "df_paragraphs[[\"PlainText\", \"CleanText\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanText</th>\n",
       "      <th>CharName</th>\n",
       "      <th>Title</th>\n",
       "      <th>GenreType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>if it be love indeed  tell me how much</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>there beggary in the love that can be reckon</td>\n",
       "      <td>Antony</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>iwill set a bourn how far to be beloved</td>\n",
       "      <td>Cleopatra</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>then must thou needs find out new heaven  new ...</td>\n",
       "      <td>Antony</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>grates me  the sum</td>\n",
       "      <td>Antony</td>\n",
       "      <td>Antony and Cleopatra</td>\n",
       "      <td>Tragedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27583</th>\n",
       "      <td>thou hadst a clarence too  and richard kill hi...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27585</th>\n",
       "      <td>bear with me  i am hungry for revenge  and now...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27587</th>\n",
       "      <td>i call thee then vain flourish of my fortune  ...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27589</th>\n",
       "      <td>forbear to sleep the nights  and fast the days...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27591</th>\n",
       "      <td>thy woes will make them sharp  and pierce like...</td>\n",
       "      <td>Queen Margaret</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               CleanText        CharName   \n",
       "2058             if it be love indeed  tell me how much        Cleopatra  \\\n",
       "2059       there beggary in the love that can be reckon           Antony   \n",
       "2060            iwill set a bourn how far to be beloved        Cleopatra   \n",
       "2061   then must thou needs find out new heaven  new ...          Antony   \n",
       "2064                                 grates me  the sum           Antony   \n",
       "...                                                  ...             ...   \n",
       "27583  thou hadst a clarence too  and richard kill hi...  Queen Margaret   \n",
       "27585  bear with me  i am hungry for revenge  and now...  Queen Margaret   \n",
       "27587  i call thee then vain flourish of my fortune  ...  Queen Margaret   \n",
       "27589  forbear to sleep the nights  and fast the days...  Queen Margaret   \n",
       "27591  thy woes will make them sharp  and pierce like...  Queen Margaret   \n",
       "\n",
       "                      Title GenreType  \n",
       "2058   Antony and Cleopatra   Tragedy  \n",
       "2059   Antony and Cleopatra   Tragedy  \n",
       "2060   Antony and Cleopatra   Tragedy  \n",
       "2061   Antony and Cleopatra   Tragedy  \n",
       "2064   Antony and Cleopatra   Tragedy  \n",
       "...                     ...       ...  \n",
       "27583           Richard III   History  \n",
       "27585           Richard III   History  \n",
       "27587           Richard III   History  \n",
       "27589           Richard III   History  \n",
       "27591           Richard III   History  \n",
       "\n",
       "[626 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agregamos personajes, obras y géneros en el mismo dataset\n",
    "df_dataset = df_paragraphs.merge(df_chapters.set_index(\"id\")[\"work_id\"], left_on=\"chapter_id\", right_index=True)\n",
    "df_dataset = df_dataset.merge(df_works.set_index(\"id\")[[\"Title\", \"GenreType\"]], left_on=\"work_id\", right_index=True)\n",
    "df_dataset = df_dataset.merge(df_characters.set_index('id')[\"CharName\"], left_on=\"character_id\", right_index=True).sort_index()\n",
    "df_dataset = df_dataset[[\"CleanText\", \"CharName\", \"Title\", \"GenreType\"]]\n",
    "\n",
    "# Usaremos sólo estos personajes\n",
    "characters = [\"Antony\", \"Cleopatra\", \"Queen Margaret\"]\n",
    "df_dataset = df_dataset[df_dataset[\"CharName\"].isin(characters)]\n",
    "\n",
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharName\n",
       "Antony            253\n",
       "Cleopatra         204\n",
       "Queen Margaret    169\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Párrafos por cada personaje seleccionado\n",
    "df_dataset[\"CharName\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset y Features de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset[\"CleanText\"].to_numpy()\n",
    "y = df_dataset[\"CharName\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños de Train/Test: 438/188\n"
     ]
    }
   ],
   "source": [
    "# TODO: Partir train/test 30% estratificados\n",
    "# -> Definir X_train, X_test, y_train, y_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = ...\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,# Proporcion del conjunto de test \n",
    "                                                    random_state=1,#Semilla para los sorteos aleatorios\n",
    "                                                    stratify=y, #Mantengo la proporcion de personajes\n",
    "                                                   )\n",
    "\n",
    "\n",
    "print(f\"Tamaños de Train/Test: {len(X_train)}/{len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Antony': 0.40415335463258784, 'Cleopatra': 0.3258785942492013, 'Queen Margaret': 0.26996805111821087}\n",
      "{'Antony': 0.4041095890410959, 'Cleopatra': 0.3264840182648402, 'Queen Margaret': 0.2694063926940639}\n",
      "{'Antony': 0.40425531914893614, 'Cleopatra': 0.324468085106383, 'Queen Margaret': 0.2712765957446808}\n"
     ]
    }
   ],
   "source": [
    "def count_proporciones(data):\n",
    "    return dict(sorted(zip(collections.Counter(data).keys(), [v/data.size for v in collections.Counter(data).values()])))\n",
    "#y.size\n",
    "print(count_proporciones(y))\n",
    "print(count_proporciones(y_train))\n",
    "print(count_proporciones(y_test))\n",
    "\n",
    "#TODO: Se podria crear una grafica para mostrar que las proporciones de personajes entre los \n",
    "#conjuntos originales, train y test coinciden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conteo de palabras y TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words=None, ngram_range=(1,1))\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfTransformer(use_idf=False)\n",
    "X_train_tf = tf_idf.fit_transform(X_train_counts)\n",
    "X_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Realizar PCA sobre los datos de entrenamiento\n",
    "# reductor = ...\n",
    "\n",
    "# Transformar train\n",
    "X_train_red = reductor.fit_transform(X_train_tf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de las dos primeras componentes de PCA\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for character in np.unique(y_train):\n",
    "    mask_train = y_train == character\n",
    "    ax.scatter(X_train_red[mask_train, 0], X_train_red[mask_train, 1], label=character)\n",
    "\n",
    "ax.set_title(\"PCA por personaje\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bayes_clf = MultinomialNB().fit(X_train_tf, y_train)\n",
    "\n",
    "# Ver las primeras 10 predicciones de train\n",
    "y_pred_train = bayes_clf.predict(X_train_tf)\n",
    "y_pred_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_pred):\n",
    "    return (y_true == y_pred).sum() / len(y_true)\n",
    "\n",
    "get_accuracy(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Predecir para test y ver la matriz de confusión, y reportar accuracy\n",
    "\n",
    "# X_test_counts = ...\n",
    "# X_test_tfidf = ...\n",
    "# y_test_pred = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Búsqueda de hiper-parámetros con Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# TODO: Agregar más variantes de parámetros que les parezcan relevantes\n",
    "param_sets = [{\"stop_words\": None, \"ngram\": (1,2), \"idf\": True},\n",
    "             {\"stop_words\": None, \"ngram\": (1,1), \"idf\": False}]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# Ahora usaremos train/validation/test\n",
    "# Por lo tanto le renombramos train+validation = dev(elopment) dataset\n",
    "X_dev = X_train\n",
    "y_dev = y_train\n",
    "\n",
    "# # Para evitar errores\n",
    "# del X_train\n",
    "# del y_train\n",
    "\n",
    "for params in param_sets:\n",
    "    \n",
    "    # Transormaciones a aplicar (featurizers)\n",
    "    count_vect = CountVectorizer(stop_words=params[\"stop_words\"], ngram_range=params[\"ngram\"])\n",
    "    tf_idf = TfidfTransformer(use_idf=params[\"idf\"])\n",
    "    \n",
    "    for train_idxs, val_idxs in skf.split(X_dev, y_dev):\n",
    "        \n",
    "        # Train y validation para el split actual\n",
    "        X_train_ = X_dev[train_idxs]\n",
    "        y_train_ = y_dev[train_idxs]\n",
    "        X_val = X_dev[val_idxs]\n",
    "        y_val = y_dev[val_idxs]\n",
    "        \n",
    "        # Ajustamos y transformamos Train\n",
    "        X_train_counts = count_vect.fit_transform(X_train_)\n",
    "        X_train_tf = tf_idf.fit_transform(X_train_counts)\n",
    "        \n",
    "        # TODO: Completar el código para entrenar y evaluar \n",
    "        \n",
    "        # Entrenamos con Train\n",
    "        # bayes_clf = ...\n",
    "\n",
    "        # Transformamos Validation\n",
    "        # X_val_counts = ...\n",
    "        # X_val_tfidf = ...\n",
    "        \n",
    "        # Predecimos y evaluamos en Validation\n",
    "        y_pred_val = bayes_clf.predict(X_val_tfidf)\n",
    "        acc = get_accuracy(y_val, y_pred_val)\n",
    "        print(f\"{acc=:.4f} {params=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Opcional) Comparativa con Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "y_train_s = np.char.replace(y_train.astype(str), \" \", \"_\").astype(object)\n",
    "y_test_s = np.char.replace(y_test.astype(str), \" \", \"_\").astype(object)\n",
    "\n",
    "# Convertimos al formato de fasttext: archivo de texto donde cada línea es:\n",
    "# __label__<label> TEXTO\n",
    "Xytrains = \"__label__\" + y_train_s.astype(object) + \" \" + X_train\n",
    "Xytests = \"__label__\" + y_test_s.astype(object) + \" \" + X_test\n",
    "np.savetxt(data_dir / \"train.txt\", Xytrains, fmt=\"%s\")\n",
    "np.savetxt(data_dir / \"test.txt\", Xytests, fmt=\"%s\")\n",
    "\n",
    "Xytests[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=str(data_dir / \"train.txt\"), epoch=100, wordNgrams=2)\n",
    "model.test(str(data_dir / \"test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out = model.predict(list(X_test))\n",
    "y_pred_test = [y[0].replace(\"__label__\", \"\") for y in y_out[0]]\n",
    "    \n",
    "print(get_accuracy(y_test_s, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
